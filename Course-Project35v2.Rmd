---
output: html_document
---
# Course Project for course "Practical Machine Learning"

## Summary
This analysis uses a machine learning algorithm to predict certain workout activities from
a set of measurements taken for the purpose of human activity recognition. A good predictive
accuracy is achieved using the random forest method.

## Data Acquisition and Data Preparation
Data was downloaded form http://groupware.les.inf.puc-rio.br/har
It was originally used for this publication:
Ugulino, W.; Cardador, D.; Vega, K.; Velloso, E.; Milidiu, R.; Fuks, H. Wearable Computing: Accelerometers' Data Classification of Body Postures and Movements. Proceedings of 21st Brazilian Symposium on Artificial Intelligence. Advances in Artificial Intelligence - SBIA 2012. In: Lecture Notes in Computer Science. , pp. 52-61. Curitiba, PR: Springer Berlin / Heidelberg, 2012. ISBN 978-3-642-34458-9. DOI: 10.1007/978-3-642-34459-6_6.

The data consists of 19622 training data sets (measurements) and 20 test data sets. Each measurement consists of 160 variables.

The first seven variables are of administrative nature (e.g. timestamps) and have no predictive value for unrelated datasets. They are therefore dropped from the training dataset.

The outcome (one of five categories "A" through "E" with A representing the proper weightlifting exercise and B-E certain mistakes in doing the exercises) is converted to a factor variable.

The dataset has a large number of missing values (NA) in it. This causes problems with the machine learning algorithms used in this analysis. Therefore all variables with at least 50 missing values in the training set are dropped. 53 variables (i.e. 52 predictors) remain after this step.

Finally, 75% of the training data set is used to train models while 25% of it are set aside for cross-validation purposes.

```{r, message=FALSE}
library(caret)
library(randomForest)
library(rpart)
library(rattle)
pmlTrain <- read.csv("pml-training.csv",header=TRUE,sep=",",stringsAsFactors=FALSE)
pmlTest <- read.csv("pml-testing.csv",header=TRUE,sep=",",stringsAsFactors=FALSE)
pmlTrainSub<-pmlTrain[,-c(1,2,3,4,5,6,7)]
pmlTrainSub$classe<-factor(pmlTrainSub$classe)
pmlTrainSub[pmlTrainSub==""] <- NA
NAcols <- rep(FALSE, ncol(pmlTrainSub))
for (i in 1:ncol(pmlTrainSub)) {
        if( sum(is.na(pmlTrainSub[,i])) > 50) {
                NAcols[i] <- TRUE
        }
}
pmlTrainSub2 <- pmlTrainSub[,!NAcols]
dim(pmlTrainSub2)
set.seed(12345)
inTrain <- createDataPartition(pmlTrainSub2$classe, p = 0.75, list=FALSE)
training <- pmlTrainSub2[inTrain,]
crossval <- pmlTrainSub2[-inTrain,]
```

## Model Fitting
Several machine learning algorithms were tried out, including random forests, classification trees and model based predictions using "Naive Bayes" and "Linear Discriminant Analysis" methods. It turned out that the random forest approach gave the best predictive performance.

However, if trying to fit the random forest with all 53 variables the computing time is prohibitive. Therefore the number of variables was further reduced by removing variables which were higly correlated to other variables in the data set. This leaves 22 variables (21 predictors) for the final fit.
These predictor variables are:
* gyros_belt_x, gyros_belt_y, gyros_belt_z
* magnet_belt_z
* roll_arm, pitch_arm, yaw_arm, total_accel_arm
* gyros_arm_x, gyros_arm_z
* roll_dumbbell, pitch_dumbbell
* gyros_dumbbell_z
* roll_forearm, pitch_forearm, yaw_forearm
* total_accel_forearm, gyros_forearm_x, accel_forearm_z, magnet_forearm_x, magnet_forearm_y       

```{r}
corMat <- cor(training[,-dim(training)[2]],)
highlyCor <- findCorrelation(corMat, cutoff = 0.5)
smallTraining <- training[,-highlyCor]
model1 <- train(classe ~ .,method="rf",data=smallTraining,trControl=trainControl(method="cv"),importance=TRUE,proximity=TRUE)
model1$finalModel
crossvalPred <- predict(model1, newdata=crossval)
confusionMat <- confusionMatrix(crossvalPred, crossval$classe)
confusionMat$table
crossvalAcc <- sum((crossvalPred==crossval$classe))/dim(crossval)[1]
crossvalAcc
```

As seen from the R output, the cross validation based on the 25% percent of training data set aside for cross validation yields an accuracy of about 98.5%. So the out-of-sample-error is 1.5% (100% minus 98.5% because the cross validation data wasn't used in training the model). The rather high accuracy justifies the choices for the cutoffs for correlated predictors (0.5) and variables dropped due to NAs (>50 NAs in training data set).

There are four predictor variables which are most important for the fit, namely pitch_forearm, magnet_belt_z, roll_forearm and roll_dumbbell, as can be seen in this plot:
```{r}
par(mar=c(3,2,3,2))
varImpPlot(model1$finalModel,type=2,sort=TRUE,main="Variable importance in model fit",pch=19,col="purple")
```

The following plot shows the error rates for the five outcomes of "classe" as a function of the number of trees in the random forest:
```{r}
layout(matrix(c(1,2),nrow=1), width=c(4,1)) 
plot(model1$finalModel,log="y")
legend("top", colnames(model1$err.rate),col=1:5,cex=0.8,fill=1:5)
MDSplot(model1$finalModel)
```

The model is then used to predict activities for the 20 test cases:
```{r}
predict(model1, pmlTest)
```
These predictions were submitted to the auto-grader and resulted in a grade of 100%.

Inspiration from work by Aous Abdo was used in this analysis.